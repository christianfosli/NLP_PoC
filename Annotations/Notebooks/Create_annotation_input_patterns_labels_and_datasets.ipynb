{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "recovered-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requirements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import jsonlines\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "competitive-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#read all csv file to dataframe\n",
    "#asp\n",
    "aps_df = pd.read_csv('aps.csv', header=None, names=[\"word\", \"tag\"])\n",
    "#create_patterns(aps_df, 'aps')\n",
    "#create_label_list(aps_df, 'aps.txt')\n",
    "#ecomplience\n",
    "ecompliance_df = pd.read_csv('ecompliance.csv', header=None, names=[\"word\", \"tag\"])\n",
    "#create_patterns(ecompliance_df, 'ecompliance')\n",
    "#create_label_list(ecompliance_df, 'ecompliance.txt')\n",
    "#et\n",
    "et_df = pd.read_csv('et.csv', header=None, names=[\"word\", \"tag\"])\n",
    "#create_patterns(et_df, 'et')\n",
    "#create_label_list(et_df, 'et.txt')\n",
    "#tags from Veronika\n",
    "tv_df = pd.read_csv('Copy of tags_2.csv', sep=';')\n",
    "#create_patterns(tv_df, 'tv')\n",
    "#create_label_list(tv_df, 'tv.txt')\n",
    "df_list = [aps_df, ecompliance_df, et_df, tv_df]\n",
    "#create_example_csv(df_list)\n",
    "result = pd.concat(df_list)\n",
    "create_patterns(result, 'all_patterns')\n",
    "#create_label_list(result, 'all_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broken-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create patterns and save as jsonl\n",
    "#{\"pattern\": [{\"lower\": \"new\"}, {\"lower\": \"york\"}], \"label\": \"GPE\"}\n",
    "#{\"pattern\": \"Berlin\", \"label\": \"GPE\"}\n",
    "def create_patterns(df, filename):\n",
    "    filename = filename + '.jsonl'\n",
    "    with jsonlines.open(filename, mode='w') as writer:\n",
    "        for index, row in df.iterrows():  \n",
    "            text = json.dumps({'pattern' : row['word'].lower(), 'label' : row['tag'].upper()})\n",
    "            text = json.loads(text)\n",
    "            writer.write(text)\n",
    "\n",
    "#create label lists\n",
    "#asp\n",
    "#ecomplience\n",
    "#et\n",
    "#tags from Veronika\n",
    "def create_label_list(df, filename):\n",
    "    label_list = []\n",
    "    list_file = open(filename, 'a', encoding='utf8')\n",
    "    for index, row in df.iterrows():\n",
    "        label = row['tag'].upper().lstrip()\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)\n",
    "            list_file.write(label + ' \\n')\n",
    "                \n",
    "            \n",
    "#create csv with examples \n",
    "def create_example_csv(df_list):\n",
    "    result = pd.concat(df_list)\n",
    "    result.to_csv('examples_words_classes_en.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.read_csv('english.csv', header=None, names=[\"label\" , \"scLabel\" , \"sc2Label\"], sep=',')\n",
    "ecompliance_df = pd.read_csv('ecompliance.csv', header=None, names=[\"label\" , \"scLabel\" , \"sc2Label\"], sep=',')\n",
    "df_list = [en_df, ecompliance_df]\n",
    "new_df = pd.concat(df_list)\n",
    "\n",
    "label_list_all = []\n",
    "label_list_super = []\n",
    "label_list_sub = []\n",
    "#list_all = open('klasseeksempler_en.txt', 'a', encoding='utf8')\n",
    "#list_super = open('superclass.txt', 'a', encoding='utf8')\n",
    "list_sub = open('super_and_subclass.txt', 'a', encoding='utf8')\n",
    "for index, row in new_df.iterrows():\n",
    "    label = row['label'].upper().lstrip()\n",
    "    if label not in label_list_super:\n",
    "        label_list_super.append(label)\n",
    "        #list_super.write(label + ' \\n')\n",
    "    suclass1 = ''\n",
    "    if row['scLabel'] is not None and type(row['scLabel'] )!= float:\n",
    "        subclass1 = row['scLabel'].upper().lstrip()\n",
    "        if subclass1 not in label_list_sub:\n",
    "            label_list_sub.append(subclass1)\n",
    "            list_sub.write(subclass1 + '\\n')\n",
    "            print(subclass1)\n",
    "            if label not in label_list_sub:\n",
    "                list_sub.write(label + '\\n')\n",
    "                label_list_sub.append(label)\n",
    "    subsub = row['sc2Label']\n",
    "    if subsub == 'NaN' or type(subsub) == float:\n",
    "        subsub = ''\n",
    "    all_str = 'Hovedklasse: ' + label +'. Underklasse 1: '+ subclass1 + '. Underklasse 2: '+ subsub +'\\n'\n",
    "    #list_all.write(all_str)\n",
    "         \n",
    "#list_all.close()\n",
    "#list_super.close()\n",
    "list_sub.close()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
