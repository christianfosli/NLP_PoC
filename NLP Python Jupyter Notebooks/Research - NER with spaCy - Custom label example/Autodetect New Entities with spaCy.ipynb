{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in /opt/conda/lib/python3.8/site-packages (2.3.5)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.19.4)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.8/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (4.51.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy) (49.6.0.post20201009)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /opt/conda/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20201009)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the pipeline component\n",
    "ner=nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New label to add\n",
    "LABEL = \"FOOD\"\n",
    "\n",
    "# Training examples in the required format\n",
    "TRAIN_DATA =[ (\"Pizza is a common fast food.\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"Pasta is an italian recipe\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"China's noodles are very famous\", {\"entities\": [(8,14, \"FOOD\")]}),\n",
    "              (\"Shrimps are famous in China too\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Lasagna is another classic of Italy\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Sushi is extemely famous and expensive Japanese dish\", {\"entities\": [(0,5, \"FOOD\")]}),\n",
    "              (\"Unagi is a famous seafood of Japan\", {\"entities\": [(0,5, \"FOOD\")]}),\n",
    "              (\"Tempura , Soba are other famous dishes of Japan\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Udon is a healthy type of noodles\", {\"entities\": [(0,4, \"ORG\")]}),\n",
    "              (\"Chocolate soufflé is extremely famous french cuisine\", {\"entities\": [(0,17, \"FOOD\")]}),\n",
    "              (\"Flamiche is french pastry\", {\"entities\": [(0,8, \"FOOD\")]}),\n",
    "              (\"Burgers are the most commonly consumed fastfood\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Burgers are the most commonly consumed fastfood\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Frenchfries are considered too oily\", {\"entities\": [(0,11, \"FOOD\")]})\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new label to ner\n",
    "ner.add_label(LABEL)\n",
    "\n",
    "# Resume training\n",
    "optimizer = nlp.resume_training()\n",
    "move_names = list(ner.move_names)\n",
    "\n",
    "# List of pipes you want to train\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "# List of pipes which should remain unaffected in training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"China's noodles are very famous\" with entities \"[(8, 14, 'FOOD')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 9.67839777469635}\n",
      "Losses {'ner': 16.28438338706738}\n",
      "Losses {'ner': 20.949838299066812}\n",
      "Losses {'ner': 30.556954653706782}\n",
      "Losses {'ner': 31.811866705411767}\n",
      "Losses {'ner': 38.56815944667966}\n",
      "Losses {'ner': 42.88868973846876}\n",
      "Losses {'ner': 52.91209392011631}\n",
      "Losses {'ner': 60.25382624328602}\n",
      "Losses {'ner': 66.42045055970783}\n",
      "Losses {'ner': 70.02622355604845}\n",
      "Losses {'ner': 79.05023038133814}\n",
      "Losses {'ner': 84.92190832067686}\n",
      "Losses {'ner': 90.91724518109518}\n",
      "Losses {'ner': 4.7757932296954095}\n",
      "Losses {'ner': 8.288377240889155}\n",
      "Losses {'ner': 18.575444773428522}\n",
      "Losses {'ner': 22.222162102812188}\n",
      "Losses {'ner': 25.462127272560945}\n",
      "Losses {'ner': 33.04097256429411}\n",
      "Losses {'ner': 37.237568848851126}\n",
      "Losses {'ner': 43.21580649827699}\n",
      "Losses {'ner': 49.694281383502286}\n",
      "Losses {'ner': 57.65538201200722}\n",
      "Losses {'ner': 60.657538434476166}\n",
      "Losses {'ner': 62.64401739842576}\n",
      "Losses {'ner': 65.67207889511626}\n",
      "Losses {'ner': 69.89804507741216}\n",
      "Losses {'ner': 2.611423085350907}\n",
      "Losses {'ner': 9.49993257535425}\n",
      "Losses {'ner': 15.724990173702736}\n",
      "Losses {'ner': 24.67406330162808}\n",
      "Losses {'ner': 28.341391047532994}\n",
      "Losses {'ner': 40.33220567374988}\n",
      "Losses {'ner': 45.618343728198994}\n",
      "Losses {'ner': 51.52756483827139}\n",
      "Losses {'ner': 55.800950171958135}\n",
      "Losses {'ner': 59.536014386024505}\n",
      "Losses {'ner': 68.54504981407914}\n",
      "Losses {'ner': 75.46889568636212}\n",
      "Losses {'ner': 77.75291474894144}\n",
      "Losses {'ner': 86.15542479590036}\n",
      "Losses {'ner': 4.611877100076526}\n",
      "Losses {'ner': 10.491362866247073}\n",
      "Losses {'ner': 13.326085292044809}\n",
      "Losses {'ner': 18.08512167889603}\n",
      "Losses {'ner': 21.039552441108754}\n",
      "Losses {'ner': 23.38747760584556}\n",
      "Losses {'ner': 29.836433581318488}\n",
      "Losses {'ner': 33.272597213284826}\n",
      "Losses {'ner': 38.02171199156328}\n",
      "Losses {'ner': 42.75120906664415}\n",
      "Losses {'ner': 45.686296910005694}\n",
      "Losses {'ner': 48.50884423072239}\n",
      "Losses {'ner': 49.79720479432399}\n",
      "Losses {'ner': 51.96351278633301}\n",
      "Losses {'ner': 3.3658062996109948}\n",
      "Losses {'ner': 6.544233274064027}\n",
      "Losses {'ner': 11.526216729893349}\n",
      "Losses {'ner': 15.795111491694115}\n",
      "Losses {'ner': 23.51294998836238}\n",
      "Losses {'ner': 26.153678293107077}\n",
      "Losses {'ner': 27.678660957695683}\n",
      "Losses {'ner': 32.04345888525131}\n",
      "Losses {'ner': 37.30704730559955}\n",
      "Losses {'ner': 42.56852412034641}\n",
      "Losses {'ner': 50.13347242024611}\n",
      "Losses {'ner': 53.98894414523966}\n",
      "Losses {'ner': 55.35764335814747}\n",
      "Losses {'ner': 60.40131651304546}\n",
      "Losses {'ner': 2.5529103726148605}\n",
      "Losses {'ner': 3.9856392063666135}\n",
      "Losses {'ner': 7.950868017273024}\n",
      "Losses {'ner': 11.352491222089157}\n",
      "Losses {'ner': 13.751108170254156}\n",
      "Losses {'ner': 19.37480519754172}\n",
      "Losses {'ner': 20.759353734276374}\n",
      "Losses {'ner': 27.18714075507887}\n",
      "Losses {'ner': 31.035712920784135}\n",
      "Losses {'ner': 34.46456449730613}\n",
      "Losses {'ner': 37.4536001135275}\n",
      "Losses {'ner': 43.11054075254651}\n",
      "Losses {'ner': 47.5375685159961}\n",
      "Losses {'ner': 51.91230255867413}\n",
      "Losses {'ner': 0.1736256256699562}\n",
      "Losses {'ner': 4.443641216494143}\n",
      "Losses {'ner': 9.335754917003214}\n",
      "Losses {'ner': 12.021509695070563}\n",
      "Losses {'ner': 19.58334850074607}\n",
      "Losses {'ner': 21.258077515405603}\n",
      "Losses {'ner': 28.924773816484958}\n",
      "Losses {'ner': 32.66909848572686}\n",
      "Losses {'ner': 36.47279078187421}\n",
      "Losses {'ner': 39.094521664315835}\n",
      "Losses {'ner': 43.435832229908556}\n",
      "Losses {'ner': 48.05748185451375}\n",
      "Losses {'ner': 49.65632630354958}\n",
      "Losses {'ner': 54.33054701698711}\n",
      "Losses {'ner': 3.066715100656438}\n",
      "Losses {'ner': 6.996185302377853}\n",
      "Losses {'ner': 11.060763365174353}\n",
      "Losses {'ner': 14.24404729768139}\n",
      "Losses {'ner': 19.695496945227205}\n",
      "Losses {'ner': 26.970406028027355}\n",
      "Losses {'ner': 29.279496474242478}\n",
      "Losses {'ner': 32.03521076967445}\n",
      "Losses {'ner': 34.682950508424256}\n",
      "Losses {'ner': 37.166230883791286}\n",
      "Losses {'ner': 43.55590491403564}\n",
      "Losses {'ner': 44.90155790873541}\n",
      "Losses {'ner': 49.903738719753164}\n",
      "Losses {'ner': 53.764612016610045}\n",
      "Losses {'ner': 0.9827240290251211}\n",
      "Losses {'ner': 1.0865227199174115}\n",
      "Losses {'ner': 4.8011368029765435}\n",
      "Losses {'ner': 9.164303148725594}\n",
      "Losses {'ner': 14.025685160049761}\n",
      "Losses {'ner': 15.05120202964099}\n",
      "Losses {'ner': 16.194160013026703}\n",
      "Losses {'ner': 19.19696717642728}\n",
      "Losses {'ner': 23.852996311416064}\n",
      "Losses {'ner': 26.68696713846657}\n",
      "Losses {'ner': 29.059146463321667}\n",
      "Losses {'ner': 31.07020629568069}\n",
      "Losses {'ner': 37.7647973522362}\n",
      "Losses {'ner': 41.009591930062015}\n",
      "Losses {'ner': 6.378709101816639}\n",
      "Losses {'ner': 8.78998924773532}\n",
      "Losses {'ner': 13.88694980256605}\n",
      "Losses {'ner': 14.944600752837687}\n",
      "Losses {'ner': 18.728918242551117}\n",
      "Losses {'ner': 27.087682950593262}\n",
      "Losses {'ner': 30.072586782093822}\n",
      "Losses {'ner': 36.125231872129916}\n",
      "Losses {'ner': 39.636498032886266}\n",
      "Losses {'ner': 50.012966981906175}\n",
      "Losses {'ner': 53.25757763749334}\n",
      "Losses {'ner': 56.454850158471345}\n",
      "Losses {'ner': 59.07026196235438}\n",
      "Losses {'ner': 61.361137596969456}\n",
      "Losses {'ner': 4.886403288692236}\n",
      "Losses {'ner': 10.239618325605989}\n",
      "Losses {'ner': 15.155427540652454}\n",
      "Losses {'ner': 20.113276721909642}\n",
      "Losses {'ner': 22.952026868239045}\n",
      "Losses {'ner': 26.140812875702977}\n",
      "Losses {'ner': 28.748363414779305}\n",
      "Losses {'ner': 31.69877729495056}\n",
      "Losses {'ner': 36.83007753677339}\n",
      "Losses {'ner': 39.06552656171516}\n",
      "Losses {'ner': 41.40982235166848}\n",
      "Losses {'ner': 47.08674003628221}\n",
      "Losses {'ner': 52.95341157612529}\n",
      "Losses {'ner': 56.67690658548054}\n",
      "Losses {'ner': 3.4656665101647377}\n",
      "Losses {'ner': 7.022892784327269}\n",
      "Losses {'ner': 11.049606111831963}\n",
      "Losses {'ner': 16.829189472831786}\n",
      "Losses {'ner': 21.509058826602995}\n",
      "Losses {'ner': 25.2675081291236}\n",
      "Losses {'ner': 28.424422653391957}\n",
      "Losses {'ner': 37.561110408976674}\n",
      "Losses {'ner': 39.62047256878577}\n",
      "Losses {'ner': 47.28212784952484}\n",
      "Losses {'ner': 48.48103509221983}\n",
      "Losses {'ner': 52.03865228717041}\n",
      "Losses {'ner': 54.695269141651806}\n",
      "Losses {'ner': 58.104808807212976}\n",
      "Losses {'ner': 2.872072589263553}\n",
      "Losses {'ner': 9.255982660368318}\n",
      "Losses {'ner': 15.657575963210547}\n",
      "Losses {'ner': 20.23861102727824}\n",
      "Losses {'ner': 22.12907757484936}\n",
      "Losses {'ner': 22.16829144555959}\n",
      "Losses {'ner': 25.583238875999086}\n",
      "Losses {'ner': 28.39169953383316}\n",
      "Losses {'ner': 35.712146799935}\n",
      "Losses {'ner': 38.85721096231646}\n",
      "Losses {'ner': 44.6514658315391}\n",
      "Losses {'ner': 50.34995002134747}\n",
      "Losses {'ner': 56.64391266156963}\n",
      "Losses {'ner': 61.79201822516552}\n",
      "Losses {'ner': 4.859878772083903}\n",
      "Losses {'ner': 10.603539252100745}\n",
      "Losses {'ner': 16.04561378652579}\n",
      "Losses {'ner': 18.7834212021844}\n",
      "Losses {'ner': 25.228276065550745}\n",
      "Losses {'ner': 31.03860514844564}\n",
      "Losses {'ner': 32.043954914093774}\n",
      "Losses {'ner': 32.29493328382523}\n",
      "Losses {'ner': 35.97835728259088}\n",
      "Losses {'ner': 38.3386225725626}\n",
      "Losses {'ner': 45.70688861860981}\n",
      "Losses {'ner': 50.04740993168525}\n",
      "Losses {'ner': 56.76260948416166}\n",
      "Losses {'ner': 61.07663514700107}\n",
      "Losses {'ner': 4.337494293926284}\n",
      "Losses {'ner': 10.565647362498567}\n",
      "Losses {'ner': 14.364332326455042}\n",
      "Losses {'ner': 24.69486463884823}\n",
      "Losses {'ner': 28.119019823614508}\n",
      "Losses {'ner': 30.633531484752893}\n",
      "Losses {'ner': 33.80538635328412}\n",
      "Losses {'ner': 38.49743908876553}\n",
      "Losses {'ner': 41.450035652611405}\n",
      "Losses {'ner': 47.64487018296495}\n",
      "Losses {'ner': 51.48987710592337}\n",
      "Losses {'ner': 56.53775049117394}\n",
      "Losses {'ner': 61.35477502387948}\n",
      "Losses {'ner': 67.13618140890321}\n",
      "Losses {'ner': 5.143144332570955}\n",
      "Losses {'ner': 6.347095071338117}\n",
      "Losses {'ner': 14.499027370475233}\n",
      "Losses {'ner': 17.331589645706117}\n",
      "Losses {'ner': 21.61470425996231}\n",
      "Losses {'ner': 24.565611540252576}\n",
      "Losses {'ner': 32.99915814297856}\n",
      "Losses {'ner': 37.89352736520232}\n",
      "Losses {'ner': 41.85072681950987}\n",
      "Losses {'ner': 42.08665823392221}\n",
      "Losses {'ner': 48.065188886195756}\n",
      "Losses {'ner': 54.38281276968155}\n",
      "Losses {'ner': 58.42753845971856}\n",
      "Losses {'ner': 59.4696160950316}\n",
      "Losses {'ner': 5.115148332668468}\n",
      "Losses {'ner': 8.31793907075189}\n",
      "Losses {'ner': 12.483797844266519}\n",
      "Losses {'ner': 16.817185435211286}\n",
      "Losses {'ner': 22.0187222098466}\n",
      "Losses {'ner': 32.09890675893985}\n",
      "Losses {'ner': 34.65303241391666}\n",
      "Losses {'ner': 40.35839792271145}\n",
      "Losses {'ner': 46.83566301449173}\n",
      "Losses {'ner': 50.07098998635047}\n",
      "Losses {'ner': 53.273829454490624}\n",
      "Losses {'ner': 55.68951071419724}\n",
      "Losses {'ner': 60.45996821641893}\n",
      "Losses {'ner': 64.968646354675}\n",
      "Losses {'ner': 3.9103013959829696}\n",
      "Losses {'ner': 7.05454298161203}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 12.030033373797778}\n",
      "Losses {'ner': 13.168758162704762}\n",
      "Losses {'ner': 17.871128900849726}\n",
      "Losses {'ner': 25.41118572553387}\n",
      "Losses {'ner': 25.699701531033497}\n",
      "Losses {'ner': 28.459521697310265}\n",
      "Losses {'ner': 33.37819176533958}\n",
      "Losses {'ner': 36.39859484223416}\n",
      "Losses {'ner': 43.03513793734601}\n",
      "Losses {'ner': 49.502771071740426}\n",
      "Losses {'ner': 53.668515345663764}\n",
      "Losses {'ner': 53.95860195590649}\n",
      "Losses {'ner': 7.996780771762133}\n",
      "Losses {'ner': 11.321786031126976}\n",
      "Losses {'ner': 14.445011986419559}\n",
      "Losses {'ner': 17.40560843097046}\n",
      "Losses {'ner': 20.127706850715185}\n",
      "Losses {'ner': 21.918902170498768}\n",
      "Losses {'ner': 26.497830624055496}\n",
      "Losses {'ner': 28.313884731676808}\n",
      "Losses {'ner': 30.36646957922494}\n",
      "Losses {'ner': 38.44291324225924}\n",
      "Losses {'ner': 41.97622516715637}\n",
      "Losses {'ner': 42.05068601352832}\n",
      "Losses {'ner': 47.61780159605405}\n",
      "Losses {'ner': 51.75337329203467}\n",
      "Losses {'ner': 3.9078431299421936}\n",
      "Losses {'ner': 6.283941769666853}\n",
      "Losses {'ner': 6.29728824346239}\n",
      "Losses {'ner': 8.299888695160917}\n",
      "Losses {'ner': 10.825393027313112}\n",
      "Losses {'ner': 16.645139101870882}\n",
      "Losses {'ner': 19.26892300108011}\n",
      "Losses {'ner': 21.791217548154236}\n",
      "Losses {'ner': 26.918658790957124}\n",
      "Losses {'ner': 29.813495346192212}\n",
      "Losses {'ner': 32.99590451813856}\n",
      "Losses {'ner': 37.693533991511686}\n",
      "Losses {'ner': 42.27742482726626}\n",
      "Losses {'ner': 50.35007090871386}\n",
      "Losses {'ner': 1.030180194764398}\n",
      "Losses {'ner': 10.20623420458287}\n",
      "Losses {'ner': 13.173605642921757}\n",
      "Losses {'ner': 17.431278072006535}\n",
      "Losses {'ner': 22.47589573886944}\n",
      "Losses {'ner': 25.67573155235732}\n",
      "Losses {'ner': 30.776626276783645}\n",
      "Losses {'ner': 34.73737400677055}\n",
      "Losses {'ner': 37.591845358299906}\n",
      "Losses {'ner': 41.70244831375021}\n",
      "Losses {'ner': 42.681598202630994}\n",
      "Losses {'ner': 47.23204969802464}\n",
      "Losses {'ner': 51.553776816945174}\n",
      "Losses {'ner': 52.57906593535154}\n",
      "Losses {'ner': 1.9877238088520244}\n",
      "Losses {'ner': 5.995668993447907}\n",
      "Losses {'ner': 13.176940233563073}\n",
      "Losses {'ner': 17.836040142108686}\n",
      "Losses {'ner': 20.24897599083488}\n",
      "Losses {'ner': 26.482726967456983}\n",
      "Losses {'ner': 26.50626719598222}\n",
      "Losses {'ner': 30.371739988629997}\n",
      "Losses {'ner': 33.54744478077191}\n",
      "Losses {'ner': 34.59433010774228}\n",
      "Losses {'ner': 38.738091856888786}\n",
      "Losses {'ner': 43.87651457996253}\n",
      "Losses {'ner': 48.76017839540873}\n",
      "Losses {'ner': 54.08397198547755}\n",
      "Losses {'ner': 2.7568610117887147}\n",
      "Losses {'ner': 7.613352320913691}\n",
      "Losses {'ner': 12.472143392835278}\n",
      "Losses {'ner': 15.626559245232784}\n",
      "Losses {'ner': 16.65294938209263}\n",
      "Losses {'ner': 22.187627900864754}\n",
      "Losses {'ner': 26.187146421063517}\n",
      "Losses {'ner': 28.702722527559672}\n",
      "Losses {'ner': 35.611332906955795}\n",
      "Losses {'ner': 40.81738659340044}\n",
      "Losses {'ner': 44.95022719611734}\n",
      "Losses {'ner': 44.959039207786645}\n",
      "Losses {'ner': 48.356667976017434}\n",
      "Losses {'ner': 54.69192710251673}\n",
      "Losses {'ner': 3.3979467289173044}\n",
      "Losses {'ner': 4.691499876033049}\n",
      "Losses {'ner': 9.606087418447714}\n",
      "Losses {'ner': 13.386139701517095}\n",
      "Losses {'ner': 17.097133093910088}\n",
      "Losses {'ner': 22.62530292330848}\n",
      "Losses {'ner': 27.035468003527058}\n",
      "Losses {'ner': 30.065774990816863}\n",
      "Losses {'ner': 32.487498296299464}\n",
      "Losses {'ner': 35.58588674013731}\n",
      "Losses {'ner': 36.80397610984505}\n",
      "Losses {'ner': 42.03832363955439}\n",
      "Losses {'ner': 44.86437825900498}\n",
      "Losses {'ner': 51.322085759090214}\n",
      "Losses {'ner': 4.850991248502396}\n",
      "Losses {'ner': 7.2296419209946805}\n",
      "Losses {'ner': 11.777869870993953}\n",
      "Losses {'ner': 11.877873770756622}\n",
      "Losses {'ner': 15.33680140520525}\n",
      "Losses {'ner': 18.737391412398637}\n",
      "Losses {'ner': 20.952379513864976}\n",
      "Losses {'ner': 29.064920896997315}\n",
      "Losses {'ner': 32.13646279529912}\n",
      "Losses {'ner': 36.30795145235272}\n",
      "Losses {'ner': 37.39683916468886}\n",
      "Losses {'ner': 39.57946896369351}\n",
      "Losses {'ner': 41.843288587199204}\n",
      "Losses {'ner': 48.03333406537087}\n",
      "Losses {'ner': 4.272806676453911}\n",
      "Losses {'ner': 7.57230192743009}\n",
      "Losses {'ner': 8.65911801456241}\n",
      "Losses {'ner': 10.20069034525659}\n",
      "Losses {'ner': 15.984242774371523}\n",
      "Losses {'ner': 22.125867313523486}\n",
      "Losses {'ner': 25.69169886837335}\n",
      "Losses {'ner': 27.154209291602456}\n",
      "Losses {'ner': 30.797504761121672}\n",
      "Losses {'ner': 36.23137519588272}\n",
      "Losses {'ner': 38.54134507807248}\n",
      "Losses {'ner': 42.62953298004504}\n",
      "Losses {'ner': 44.452723929870444}\n",
      "Losses {'ner': 51.21668431400667}\n",
      "Losses {'ner': 5.599818983813748}\n",
      "Losses {'ner': 10.192372894836808}\n",
      "Losses {'ner': 14.04503873394242}\n",
      "Losses {'ner': 17.2540547385197}\n",
      "Losses {'ner': 22.51219964534903}\n",
      "Losses {'ner': 22.513890072925342}\n",
      "Losses {'ner': 24.473699848003953}\n",
      "Losses {'ner': 28.362501652474812}\n",
      "Losses {'ner': 31.82923464060884}\n",
      "Losses {'ner': 32.826775064604654}\n",
      "Losses {'ner': 35.51603830422432}\n",
      "Losses {'ner': 37.029177666249275}\n",
      "Losses {'ner': 39.28354495724529}\n",
      "Losses {'ner': 43.190675032863915}\n",
      "Losses {'ner': 4.561676748096943}\n",
      "Losses {'ner': 8.583540942287073}\n",
      "Losses {'ner': 12.733365890690038}\n",
      "Losses {'ner': 13.980686783423153}\n",
      "Losses {'ner': 13.983224946819192}\n",
      "Losses {'ner': 14.950207389240987}\n",
      "Losses {'ner': 17.32317835464086}\n",
      "Losses {'ner': 23.91027877106275}\n",
      "Losses {'ner': 27.227017254234525}\n",
      "Losses {'ner': 29.662085199309004}\n",
      "Losses {'ner': 31.514216571784928}\n",
      "Losses {'ner': 35.3700922098317}\n",
      "Losses {'ner': 36.410376171369776}\n",
      "Losses {'ner': 36.41746652269468}\n",
      "Losses {'ner': 3.3597644076362485}\n",
      "Losses {'ner': 4.3606521094336586}\n",
      "Losses {'ner': 8.510999596116655}\n",
      "Losses {'ner': 13.73548630196374}\n",
      "Losses {'ner': 21.66766954400746}\n",
      "Losses {'ner': 26.358848730113188}\n",
      "Losses {'ner': 32.26359435043182}\n",
      "Losses {'ner': 35.98323654721376}\n",
      "Losses {'ner': 35.983500653657735}\n",
      "Losses {'ner': 44.5204820574854}\n",
      "Losses {'ner': 46.94135796590488}\n",
      "Losses {'ner': 47.90000607121642}\n",
      "Losses {'ner': 53.21169335442705}\n",
      "Losses {'ner': 56.73401202595337}\n",
      "Losses {'ner': 7.746105939149857}\n",
      "Losses {'ner': 10.373354934128244}\n",
      "Losses {'ner': 10.37789204582809}\n",
      "Losses {'ner': 15.25826188788055}\n",
      "Losses {'ner': 16.223222064513784}\n",
      "Losses {'ner': 22.951987097699266}\n",
      "Losses {'ner': 26.007590523333484}\n",
      "Losses {'ner': 27.713066525169843}\n",
      "Losses {'ner': 33.63830512216288}\n",
      "Losses {'ner': 39.67470221677292}\n",
      "Losses {'ner': 48.29672568374742}\n",
      "Losses {'ner': 52.62270375676241}\n",
      "Losses {'ner': 56.08515400634867}\n",
      "Losses {'ner': 59.2180604620117}\n"
     ]
    }
   ],
   "source": [
    "# Importing requirements\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "\n",
    "# Begin training by disabling other pipeline components\n",
    "with nlp.disable_pipes(*other_pipes) :\n",
    "\n",
    "  sizes = compounding(1.0, 4.0, 1.001)\n",
    "  # Training for 30 iterations     \n",
    "  for itn in range(30):\n",
    "    # shuffle examples before training\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAIN_DATA, size=sizes)\n",
    "    # ictionary to store losses\n",
    "    losses = {}\n",
    "    for batch in batches:\n",
    "      texts, annotations = zip(*batch)\n",
    "      # Calling update() over the iteration\n",
    "      nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "      print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in 'I ate Sushi yesterday. Maggi is a common fast food '\n",
      "Sushi\n",
      "Maggi\n"
     ]
    }
   ],
   "source": [
    "# Testing the NER\n",
    "\n",
    "test_text = \"I ate Sushi yesterday. Maggi is a common fast food \"\n",
    "doc = nlp(test_text)\n",
    "print(\"Entities in '%s'\" % test_text)\n",
    "for ent in doc.ents:\n",
    "  print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to content\n",
      "Loading from content\n",
      "FOOD Dosa\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "from pathlib import Path\n",
    "output_dir=Path('./content/')\n",
    "\n",
    "# Saving the model to the output directory\n",
    "if not output_dir.exists():\n",
    "  output_dir.mkdir()\n",
    "nlp.meta['name'] = 'my_ner'  # rename model\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "\n",
    "# Loading the model from the directory\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "doc2 = nlp2(' Dosa is an extremely famous south Indian dish')\n",
    "for ent in doc2.ents:\n",
    "  print(ent.label_, ent.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
